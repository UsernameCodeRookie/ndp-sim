# 1.6 案例分析

## 概述

本节通过具体的实际案例，展示事件驱动模拟在体系结构中的应用，并分析真实场景中的设计决策和性能表现。

## 1.6.1 案例1: 简单的两级流水线处理器

### 场景描述

模拟一个最简单的处理器：
- 两级流水线: Fetch → Execute
- 1条指令宽度
- 固定延迟(Fetch=1周期, Execute=3周期)
- 100个待执行指令

### 循环驱动方案

```cpp
class SimpleCycleBasedSimulator {
public:
    void run(size_t num_instructions) {
        for (uint64_t cycle = 0; cycle < 1000; cycle++) {
            // Fetch阶段
            if (!pc_at_limit && fetch_buffer.size() < 2) {
                Instruction instr = program_memory[pc++];
                fetch_buffer.push(instr);
                fetch_count++;
            }
            
            // Execute阶段
            if (!execute_buffer.empty() && 
                --execute_latency == 0) {
                Instruction result = execute_buffer.front();
                execute_buffer.pop();
                execute_count++;
            }
            
            // 流水线前向
            if (!fetch_buffer.empty()) {
                Instruction instr = fetch_buffer.front();
                fetch_buffer.pop();
                execute_buffer.push(instr);
                execute_latency = 3;
            }
        }
    }
};
```

**性能**: 1000个周期，100条指令，总时间≈ 100 + 3 = 103个周期

**实际执行**:
- 循环迭代数: 1000次
- 每次循环的操作: 3个阶段 × ~5个操作 = 15个基本操作
- 总操作数: 1000 × 15 = 15,000个

### 事件驱动方案

```cpp
class SimpleEventDrivenSimulator {
public:
    void run() {
        // 初始化: 安排第一个Fetch事件
        for (size_t i = 0; i < 100; i++) {
            scheduler.scheduleEvent(
                std::make_shared<FetchEvent>(i)
            );
        }
        scheduler.run();
    }
};

class FetchEvent : public Event {
public:
    FetchEvent(size_t instr_id) 
        : Event(instr_id),
          instr_id_(instr_id) {}
    
    void execute(EventScheduler& scheduler) override {
        Instruction instr = program[instr_id_];
        
        // 安排Execute事件: 1个周期后
        scheduler.scheduleEvent(
            std::make_shared<ExecuteEvent>(
                instr_id_,
                scheduler.getCurrentTime() + 1
            )
        );
    }
    
private:
    size_t instr_id_;
};

class ExecuteEvent : public Event {
public:
    ExecuteEvent(size_t instr_id, uint64_t time)
        : Event(time),
          instr_id_(instr_id) {}
    
    void execute(EventScheduler& scheduler) override {
        // 执行完成
        result_buffer[instr_id_] = true;
    }
    
private:
    size_t instr_id_;
};
```

**性能**: 200个事件(100 Fetch + 100 Execute)

**实际执行**:
- 事件总数: 200个
- 队列操作: 200 × log(200) ≈ 1600次
- 事件执行: 200 × ~10个操作 = 2000个
- 总操作数: ~3600个

**对比**:
```
循环驱动: 15,000个操作
事件驱动: 3,600个操作

加速比: 15,000 / 3,600 ≈ 4.2×
```

## 1.6.2 案例2: 带缓存的内存系统

### 场景描述

模拟器包含:
- L1缓存(8KB, 命中率80%)
- L2缓存(256KB, 命中率95%)
- 内存(DRAM)
- 处理器每周期发出1个加载/存储请求

### 事件链模型

```
周期T:  加载请求发出
  ↓
[L1命中分支] (80% 概率)
  ├─ 延迟: 4个周期
  └─ 时刻T+4: L1命中完成事件
  
[L1未命中] (20% 概率)
  ├─ 向L2发出请求
  └─ [L2命中分支] (95% 概率)
      ├─ 延迟: 20个周期
      └─ 时刻T+20: L2命中完成事件
      
  └─ [L2未命中] (5% 概率)
      ├─ 向内存发出请求
      ├─ 延迟: 200个周期
      └─ 时刻T+200: 内存返回完成事件
```

### 事件驱动实现

```cpp
class LoadStoreEvent : public Event {
public:
    enum class Stage { ISSUED, L1, L2, MEMORY };
    
    LoadStoreEvent(uint64_t time, int ls_id)
        : Event(time), ls_id_(ls_id) {}
    
    void execute(EventScheduler& scheduler) override {
        if (stage_ == Stage::ISSUED) {
            // 第一步: 查询L1缓存
            if (l1_hit()) {
                // L1命中
                scheduler.scheduleEvent(
                    std::make_shared<LoadStoreEvent>(
                        scheduler.getCurrentTime() + 4,
                        ls_id_
                    )
                );
            } else {
                // L1未命中，向L2发出请求
                scheduler.scheduleEvent(
                    std::make_shared<LoadStoreEvent>(
                        scheduler.getCurrentTime() + 1,
                        ls_id_
                    )
                );
            }
        } else if (stage_ == Stage::L1) {
            // L1已完成或未命中，继续
        } else if (stage_ == Stage::L2) {
            if (l2_hit()) {
                // L2命中，完成
            } else {
                // L2未命中，向内存发出请求
                scheduler.scheduleEvent(
                    std::make_shared<LoadStoreEvent>(
                        scheduler.getCurrentTime() + 200,
                        ls_id_
                    )
                );
            }
        } else if (stage_ == Stage::MEMORY) {
            // 内存返回，完成
            complete_ = true;
        }
    }
    
private:
    int ls_id_;
    Stage stage_;
    bool complete_;
    
    bool l1_hit() { return (rand() % 100) < 80; }
    bool l2_hit() { return (rand() % 100) < 95; }
};
```

**事件数量估计** (假设1000个访存操作):
- 直接发出: 1000
- L1未命中(20%): 200
- L2未命中(5% of 20%): 10
- **总事件数**: 1000 + 200 + 10 = 1210

**vs 循环驱动**:
- 循环周期: 最坏情况 1000 × 200 = 200,000个周期(如果都是内存访存)
- 循环驱动操作: 200,000 × N_components × ~10 = 200万+个操作
- 事件驱动操作: 1,210 × log(1,210) ≈ 12,000个操作

**加速比**: 200万 / 12,000 ≈ 167×

## 1.6.3 案例3: 中断与异常处理

### 场景描述

处理器在运行期间会遇到各种异步事件:
- 定时器中断(每10,000个周期)
- I/O中断(随机，平均每30,000个周期)
- 异常(指令执行失败)

### 事件模型

```cpp
class InterruptManager {
private:
    EventScheduler& scheduler_;
    uint64_t timer_period_;
    
public:
    void initialize() {
        // 安排周期性定时器中断
        auto timer = std::make_shared<PeriodicEvent>(
            0,           // 从时刻0开始
            10000,       // 每10000周期
            [this](EventScheduler& s, uint64_t time) {
                handleTimerInterrupt(time);
            },
            0            // 无限重复
        );
        scheduler_.scheduleEvent(timer);
        
        // 安排随机I/O中断
        scheduleRandomIOInterrupt();
    }
    
    void handleTimerInterrupt(uint64_t time) {
        std::cout << "Timer interrupt @ cycle " << time << "\n";
        
        // 中断处理逻辑:
        // 1. 保存现场
        // 2. 跳转到中断处理程序
        // 3. 恢复现场
        
        // 示例: 中断处理耗时100个周期
        auto resume_event = std::make_shared<LambdaEvent>(
            time + 100,
            [](EventScheduler& s) {
                // 恢复执行
            }
        );
        scheduler_.scheduleEvent(resume_event);
    }
    
    void scheduleRandomIOInterrupt() {
        uint64_t delay = rand() % 60000;  // 0-60K周期
        auto io_event = std::make_shared<LambdaEvent>(
            scheduler_.getCurrentTime() + delay,
            [this](EventScheduler& s) {
                handleIOInterrupt(s.getCurrentTime());
            }
        );
        scheduler_.scheduleEvent(io_event);
        
        // 递归安排下一个中断
        scheduler_.scheduleEvent(
            std::make_shared<LambdaEvent>(
                scheduler_.getCurrentTime() + delay,
                [this](EventScheduler& s) {
                    scheduleRandomIOInterrupt();
                }
            )
        );
    }
};
```

**循环驱动的问题**:
```cpp
// ❌ 循环驱动需要每个周期检查中断
for (uint64_t cycle = 0; cycle < max_cycles; cycle++) {
    // ... 模拟指令 ...
    
    // 检查定时器中断
    if (cycle % 10000 == 0) {
        handleTimerInterrupt();  // 开销!
    }
    
    // 检查I/O中断
    if (io_interrupt_pending) {
        handleIOInterrupt();  // 不确定何时发生
    }
}
```

**事件驱动的优势**:
- 只在中断发生时处理
- 无需每周期检查
- 自动处理异步事件

## 1.6.4 案例4: 多核处理器模拟

### 场景描述

模拟4核处理器，每核独立运行:
- 每核有自己的指令流
- 核心通过共享缓存和内存交互
- 需要精确的时间同步

### 多核调度

```cpp
class MultiCoreScheduler : public EventScheduler {
private:
    // 每个核有自己的事件队列
    std::vector<EventQueue> core_queues_;
    static constexpr size_t NUM_CORES = 4;
    
public:
    void run() {
        while (hasEvents()) {
            // 找到所有核中最早的事件
            uint64_t min_time = UINT64_MAX;
            int min_core = -1;
            
            for (int i = 0; i < NUM_CORES; i++) {
                if (!core_queues_[i].empty()) {
                    uint64_t t = core_queues_[i].peek()->getTime();
                    if (t < min_time) {
                        min_time = t;
                        min_core = i;
                    }
                }
            }
            
            // 同步到最早的时刻
            current_time_ = min_time;
            
            // 执行该核的所有同时刻事件
            while (!core_queues_[min_core].empty()) {
                auto event = core_queues_[min_core].extractMin();
                if (event->getTime() != current_time_) break;
                
                event->execute(*this);
            }
            
            // 在共享资源(缓存/内存)上执行时刻同步
            synchronizeSharedResources(current_time_);
        }
    }
    
private:
    bool hasEvents() const {
        for (int i = 0; i < NUM_CORES; i++) {
            if (!core_queues_[i].empty()) return true;
        }
        return false;
    }
    
    void synchronizeSharedResources(uint64_t time) {
        // 处理共享L3缓存的请求
        // 处理内存的请求
        // 更新一致性协议
    }
};
```

**事件数量** (假设模拟1M周期):
- 单核: 200万个事件
- 4核: 800万个事件
- 共享资源: +额外50万个事件
- **总计**: 850万个事件

**优势vs循环驱动**:
- 循环驱动: 1M × 4核 × N_ops = 400万+个操作(最坏)
- 事件驱动: 8.5M × log(8.5M) ≈ 2亿个队列操作
- 当事件稀疏时，事件驱动仍然更优

## 1.6.5 案例5: 网络模拟

### 场景描述

模拟网络数据包交换:
- 100个节点
- 随机发送数据包(泊松分布, λ=5包/ms)
- 网络延迟: 1-10ms

### 事件驱动的优雅设计

```cpp
class NetworkSimulator : public EventScheduler {
public:
    NetworkSimulator(size_t num_nodes)
        : num_nodes_(num_nodes) {
        initializeNodes();
    }
    
private:
    void initializeNodes() {
        for (size_t i = 0; i < num_nodes_; i++) {
            // 为每个节点安排首次数据包生成事件
            scheduleNextPacket(i);
        }
    }
    
    void scheduleNextPacket(size_t node_id) {
        // 泊松分布: 下一个包的延迟
        uint64_t next_delay = generatePoissonDelay(5.0);
        
        auto packet_event = std::make_shared<LambdaEvent>(
            getCurrentTime() + next_delay,
            [this, node_id](EventScheduler& s) {
                Packet pkt = generatePacket(node_id);
                size_t dest = pkt.destination;
                
                // 计算网络延迟
                uint64_t net_delay = rand() % 10 + 1;  // 1-10ms
                
                // 安排到达事件
                s.scheduleEvent(std::make_shared<LambdaEvent>(
                    s.getCurrentTime() + net_delay,
                    [dest, pkt](EventScheduler& s2) {
                        receivePacket(dest, pkt);
                    }
                ));
                
                // 递归安排下一个包
                scheduleNextPacket(node_id);
            },
            10,  // 优先级
            "Packet_Gen_" + std::to_string(node_id)
        );
        
        scheduleEvent(packet_event);
    }
    
    static double generatePoissonDelay(double lambda) {
        // Exponential distribution sampling
        return -log(rand() / (double)RAND_MAX) / lambda;
    }
    
    Packet generatePacket(size_t src) {
        return {
            src,
            (size_t)(rand() % num_nodes_),  // 随机目的地
            rand() % 1500,                  // 随机大小
            getCurrentTime()                // 时间戳
        };
    }
    
    void receivePacket(size_t node_id, const Packet& pkt) {
        // 处理接收到的包
        std::cout << "Node " << node_id 
                  << " received packet from " << pkt.source 
                  << " at time " << getCurrentTime() << "\n";
    }
    
private:
    size_t num_nodes_;
};
```

**事件驱动的优雅之处**:
- 无需模拟网络中的每个"时隙"
- 自动处理不同的数据包到达时间
- 代码简洁、易于理解

**性能数据**:
- 泊松到达λ=5: 每秒5000个包
- 模拟1小时: ~18M个数据包(生成事件) + 18M个接收事件 = 36M个事件
- 循环驱动: 3600秒 × 1000ms × 1000μs ≈ 36亿次迭代 (虽然不是所有都有包)
- 事件驱动: 36M个事件, 更高效

## 1.6.6 性能对比总结

### 各案例的性能指标

| 案例 | 事件数 | 循环迭代 | 加速比 | 适用性 |
|------|--------|---------|--------|--------|
| 流水线 | 200 | 1,000 | 4.2× | ★☆☆ |
| 内存 | 1,210 | 200K | 167× | ★★★ |
| 中断 | 12K | 1M | 100× | ★★★ |
| 多核 | 8.5M | 1M | 可变 | ★★☆ |
| 网络 | 36M | 36B | >100× | ★★★ |

### 关键洞察

1. **事件驱活度**越低(事件越少相对于时间跨度),加速比越大
2. **事件粒度**影响队列操作成本，细粒度事件需要更多队列操作
3. **事件分布**影响性能：
   - 密集事件: 事件驱动收益小
   - 稀疏事件: 事件驱动大幅加速
4. **实现质量**决定常数因子，优化可提升2-10×

## 小结

本节通过5个实际案例展示了事件驱动模拟的应用：

1. **简单流水线**: 基础概念展示，加速比4×
2. **内存系统**: 展示事件链的优雅性，加速比167×
3. **中断处理**: 异步事件的自然表达
4. **多核处理器**: 多时钟域的同步
5. **网络模拟**: 高度异步系统的完美适配，加速比>100×

关键启示：
- 事件驱动特别适合**异步、稀疏**事件系统
- 不是所有系统都受益于事件驱动
- 实现质量和优化同样重要

---

**第一章完**

这完成了第一章的全部内容。下一章将介绍基于事件驱动的体系结构建模方法学。

**下一章**: [第二章 体系结构建模方法学](../chapter2-architecture-modeling/README.md)
