# 3.7 标量与向量的集成设计与性能分析

## 概述

Coral NPU的核心创新在于标量与向量执行引擎的深度集成。本节讨论两个引擎如何协同工作，以及如何通过建模框架评估集成设计的性能。

## 3.7.1 标量-向量协同的架构考量

### 执行流的分离

```
单一核心设计（Coral NPU采用）：
┌─────────────────────────┐
│   共享指令缓存 (I-Cache) │
└──────────┬──────────────┘
           │ Fetch
┌──────────▼──────────────┐
│ 共享解码单元 (Decode)   │
└──────────┬──────────────┘
           │
      ┌────┴─────┐
      │ Dispatch │ (统一dispatch单元)
      └────┬─────┘
           │
      ┌────┴────────────┐
      ▼                 ▼
  标量执行          向量执行
  (5-stage)        (3-stage)
      │                 │
      │      ┌──────────┘
      └──────┤ 共享寄存器文件？
             │ (分离设计：否)
             
关键决策：
1. 指令缓存共享（是）→ 减少面积，增加干扰
2. 解码共享（是）→ 优化面积，增加复杂性
3. 寄存器文件分离（是）→ 简化跨域转换，但需要显式指令
```

### 调度与仲裁策略

```
方案A：向量优先（当前Coral NPU）
  if (向量指令就绪):
    dispatch 向量指令
  else:
    dispatch 标量指令
  
  优点：
  - 向量指令的长延迟得到隐藏
  - 向量单元得到充分利用
  
  缺点：
  - 标量指令可能被延迟
  - 不适合标量密集工作负载

方案B：优先级动态调整
  priority = 基础优先级 + (延迟等待时间)
  
  优点：
  - 平衡两个引擎的执行
  - 自适应工作负载特性
  
  缺点：
  - 复杂的仲裁逻辑
  - 可能导致乒乓效应

方案C：周期轮转
  偶数周期dispatch标量
  奇数周期dispatch向量
  
  优点：
  - 简单，可预测
  
  缺点：
  - 无法适应工作负载变化
```

## 3.7.2 寄存器与存储的组织

### 向量-标量数据转换

```
RISC-V RVV提供的转换指令：

vmv.x.s rd, vs2 - 从向量寄存器读取第0个元素
  例：v0 = {1, 2, 3, 4}
      vmv.x.s x1, v0  →  x1 = 1
  
  成本：1周期（从向量执行引擎）

vmv.s.x vd, rs1 - 向向量寄存器写入标量
  例：x1 = 100
      vmv.s.x v0, x1  →  v0[0] = 100
  
  成本：1周期（需要vector dispatch）

向量化的标量操作：
vfmacc.vf vd, rs1, vs2 - FP乘加（标量乘以向量）
  例：vd[i] = vd[i] + rs1 * vs2[i]
  
  优点：
  - 利用向量并行性
  - 减少指令数
  - 减少标量-向量转换
```

### 存储层次的权衡

```
当前Coral NPU的存储组织：
┌──────────────────────┐
│  共享 L1 I-Cache    │ (32KB)
└──────────────────────┘
         │
      Fetch
         │
┌────────┴──────────────────────────────┐
│ RegisterFile (标量，32×32bit)          │
│ VectorRegisterFile (向量，32×VLEN-bit)│
└────────────────────────────────────────┘
         │ Load/Store
┌────────▼───────────────┐
│  L1 D-Cache (32KB)     │ (共享)
└────────────────────────┘
         │ Miss
┌────────▼───────────────┐
│  L2 Cache (256KB)      │ (可选)
└────────────────────────┘

优化方向1：向量数据缓存策略
  - 向量加载往往是流式访问（stride=1）
  - 可以使用流缓冲区（Stream Buffer）
  - 预取策略需要特殊处理

优化方向2：缓存一致性
  - 标量与向量访问同一内存位置
  - L1D缓存需要处理两种访问类型
  - Write-through vs. Write-back策略选择
```

## 3.7.3 真实工作负载案例：矩阵乘法（GEMM）

### 标量版本（Reference实现）

```
C[i][j] += A[i][k] * B[k][j]  的标量实现

标量Kernel（伪代码）：
for i in 0..M-1:
  for j in 0..N-1:
    acc = 0
    for k in 0..K-1:
      acc += A[i][k] * B[k][j]   # 需要2个load + 1个mul + 1个add
    C[i][j] = acc
```

性能分析（Coral NPU，时钟周期数）：

```
设定：M=256, N=256, K=128（256×256×128 GEMM）
总计算：256 × 256 × 128 × 2 = 16M次浮点操作

假设配置：
- L1 Hit率：95%
- L1 Hit延迟：4周期
- 存储延迟：1周期（ALU+完成）

内层循环的指令序列（K=128次）：
  load A[i][k]        (4周期)
  load B[k][j]        (4周期)
  mul                 (3周期，MLU)
  add                 (1周期，ALU)
  ─────────────────────────
  每次迭代：~4周期（load是关键路径）
  
  128次迭代 × 4周期 = 512周期
  
  加上初始化、指针管理等：~550周期

总CPI = 550周期 / 128个内层迭代 = 4.3

理想CPI = 1 (完全无依赖并行)
实际效率 = 1 / 4.3 = 23%
```

### 向量版本（RVV实现）

```
向量Kernel（RVV伪代码）：
for i in 0..M-1:
  for j in 0..N-1:
    v_acc = 0
    for k in 0..K-1 step VLMAX:
      v_a = vlw(A[i][k..k+VLMAX-1])      # 向量load
      v_b = vlw(B[k][j..k+VLMAX-1])      # 向量load (stride != 1)
      v_acc += v_a * v_b                  # 向量乘加
    C[i][j] = vredsum(v_acc)              # 向量归约
```

性能分析：

```
向量配置：VLEN=256bit（8个32-bit元素）
VLMAX = VLEN/SEW = 256/32 = 8

内层向量循环（K=128，每次处理8个元素）：
  128/8 = 16次向量迭代
  
  每次迭代：
  vlw (向量load A)     2周期（地址计算+访存）
  vlw (向量load B)     2周期
  fmacc.vv (乘加)      4周期（向量管道）
  ────────────────────
  每次迭代：~4周期
  
  16次迭代 × 4周期 = 64周期（内层）
  
  加上归约：vredsum (~8周期)
  
  总数：~72周期

向量效率 = 128个标量操作 / 72周期 = 1.78操作/周期

标量vs向量：
  标量：4.3周期/迭代 × 128次 = 550周期
  向量：4周期/向量迭代 × 16次 + 8周期 = 72周期
  
  性能提升：550 / 72 = 7.6倍
  
  理论上限：8倍（VLMAX）
  实际达成：7.6倍（接近理想）
```

## 3.7.4 建模框架中的性能评估

### 跟踪执行轨迹

建模框架的关键优势在于可以捕捉详细的执行轨迹：

```
轨迹记录点：
1. 指令级轨迹：
   [周期] PC=0x1000: addi x1, x0, 5
   [周期] PC=0x1004: vlw v0, (x1)
   [周期] PC=0x1008: vmul.vv v1, v0, v0

2. 缓存轨迹：
   [周期] L1D Hit: addr=0x8000, tag=0x2, latency=4
   [周期] L1D Miss: addr=0x8100, fill_time=25

3. 流水线事件：
   [周期] Dispatch: 指令A (stall=0)
   [周期] Dispatch: 指令B (stall=1, reason=RAW)
   [周期] Execute: 指令A (完成)

4. 汇聚统计：
   CPI: 平均周期数
   IPC: 每周期指令数
   执行单元利用率
   缓存hit率
   分支预测准确率
```

### 性能建模与预测

```
建立性能模型：

CPI = CPI_ideal + CPI_stall_RAW + CPI_stall_结构 + CPI_stall_缓存

CPI_ideal = 1（无任何延迟）

CPI_stall_RAW = (寄存器依赖深度) / (并行度)
  例：连续乘法 v0 = v1 * v2; v3 = v0 * v4
      深度 = 1，并行度 = 1
      贡献 = 1周期额外延迟

CPI_stall_结构 = (执行单元冲突次数) / (总指令数)
  例：两个乘法在同一周期需要MLU
      贡献 = 额外等待周期

CPI_stall_缓存 = (缓存miss次数) × (miss延迟) / (总指令数)
  例：100条指令中有5个L1 miss，miss延迟=20周期
      贡献 = 5 × 20 / 100 = 1周期
```

## 3.7.5 系统集成的实现细节

### 事件驱动的标量-向量协同

在建模框架中，两个执行引擎可以独立触发事件：

```cpp
// 伪代码示意
class CoreDispatcher : public Component {
  void onScalarReady() {
    if (!scalarQueue.empty() && !vectorQueue.empty()) {
      // 两个队列都有就绪指令
      Instruction scalar = scalarQueue.front();
      Instruction vector = vectorQueue.front();
      
      // 仲裁逻辑
      if (vectorPriority > scalarPriority) {
        dispatch(vector);
      } else {
        dispatch(scalar);
      }
    } else if (!scalarQueue.empty()) {
      dispatch(scalarQueue.front());
    } else if (!vectorQueue.empty()) {
      dispatch(vectorQueue.front());
    }
  }
};
```

### 性能监测点

```
关键监测指标：

1. 指令分布统计：
   - 标量指令数量
   - 向量指令数量
   - 转换指令数量（vmv.x.s, vmv.s.x）

2. 执行单元活跃度：
   - ALU utilization
   - MLU utilization
   - LSU utilization
   - Vector执行引擎utilization

3. 寄存器文件压力：
   - 标量RF读端口阻塞次数
   - 向量RF读端口阻塞次数
   - 写端口竞争

4. 存储系统特性：
   - 按指令类型分类的缓存hit/miss率
   - 按工作集大小分类的miss行为
   - 存储依赖导致的stall
```

## 3.7.6 扩展方向与未来工作

### 硬件端的优化

```
1. 增加向量执行引擎的宽度
   - 当前：8-lane（for VLEN=256, SEW=32）
   - 可扩展：16-lane（for VLEN=512, SEW=32）
   - 代价：功耗和面积成倍增加

2. 多向量操作的流水线化
   - 目前多个向量操作线性执行
   - 可以考虑向量load/execute/store的重叠

3. 向量优化的缓存策略
   - 当前：标准LRU
   - 可选：特殊的向量数据缓存策略
   - 利用访问模式的规律性（stride, sequential）
```

### 软件端的优化

```
1. 编译器优化
   - 向量化循环的自动识别
   - 内存访问模式的优化
   - 标量-向量转换指令的最小化

2. 运行时优化
   - 动态工作负载检测
   - 自适应调度策略
   - 能耗感知的执行

3. 算法级优化
   - 充分利用向量执行
   - 减少标量-向量转换开销
   - 数据局部性优化
```

## 小结

标量与向量的集成设计是Coral NPU的核心创新。通过合理的寄存器分离、dispatch仲裁、和缓存策略，可以在保持硬件复杂度相对较低的情况下，实现显著的性能提升。建模框架的优势在于可以快速评估不同设计决策的性能影响，从而指导硬件和软件的协同优化。

GEMM实验表明，标量版本约为550周期，向量版本约为72周期，性能提升接近理论上限的8倍，充分体现了向量执行的有效性。

---

**相关章节**: 
- [3.1 处理器体系架构总览](./3.1-处理器体系架构总览.md)
- [3.5 RVV向量执行引擎](./3.5-RVV向量执行引擎.md)
- [2.7 系统集成与同步机制](../chapter2-architecture-modeling/2.7-系统集成与同步机制.md)