# 3.6 微体系结构的优化与扩展

## 概述

现代处理器的性能取决于众多微体系结构优化技术的综合应用。本节讨论Coral NPU中应用或可以应用的关键优化，以及如何通过建模框架实现这些优化的精确评估。

## 3.6.1 分支预测与推测执行

### 分支预测的必要性

在深流水线中，分支指令如果不预测，会导致严重的性能损失：

```
不进行分支预测：
  t=0: Fetch分支指令
  t=1: Decode分支指令
  t=2: Dispatch分支指令（无法dispatch，不知道下一条是什么）
  t=3: Execute分支，确定目标
  t=4: 刷新流水线，Fetch目标指令
  
  总延迟：4周期（流水线深度）

使用分支预测：
  t=0: Fetch分支，预测目标（假设预测器说是分支taken）
  t=1: Decode分支，同时Fetch预测目标
  t=2: Dispatch分支和后续指令
  t=3: Execute分支，确认预测正确
  
  延迟：0周期（预测成功）
  
预测失败时：
  t=3: Execute分支，发现预测错误
  t=4: 刷新流水线，Fetch正确目标
  延迟：4周期的惩罚
```

### 分支预测器的种类

```
1. 静态预测：
   - 规则：向后分支预测为taken（循环）
   - 向前分支预测为not taken
   - 精度：~60%，简单但低精度

2. 一位计数器：
   - 为每个分支存储1-bit预测器
   - 精度：~70-80%
   - 大小：小

3. 两位计数器（饱和计数）：
   - 状态：强taken、弱taken、弱not taken、强not taken
   - 精度：~85-90%
   - 大小：中等

4. 关联预测器（Pattern History Table, PHT）：
   - 利用最近分支历史进行预测
   - 精度：~95%+
   - 大小：大（受限于寄存器文件大小）

Coral NPU使用关联预测器（推荐）
```

### 分支预测的建模

在模拟框架中，分支预测可以通过简化模型实现：

```
预测器模型（伪代码）：
class BranchPredictor:
  def predict(pc):
    history_idx = (pc ^ global_history) & mask
    counter = pht[history_idx]
    
    if counter >= threshold:
      return TAKEN
    else:
      return NOT_TAKEN
  
  def update(pc, actual_taken):
    history_idx = (pc ^ global_history) & mask
    if actual_taken:
      pht[history_idx]++
    else:
      pht[history_idx]--
    global_history = (global_history << 1) | actual_taken
```

## 3.6.2 缓存优化

### L1缓存的参数优化

```
容量的影响：
  - 32KB: 容量较小，可能频繁miss
  - 64KB: 大多数应用的良好选择
  - 128KB: 极大，面积和功耗开销
  
关联度的影响：
  - 直映(1-way): 简单快速，但冲突miss多
  - 2-way: 降低冲突miss，性能提升明显
  - 4-way: 进一步降低冲突，面积开销增加
  - 8-way: 高关联，性能增益有限

行大小的影响：
  - 32字节: 简单，但利用率低
  - 64字节: 常见选择，充分利用总线带宽
  - 128字节: 面积大，总线利用率可能过度
```

### 缓存替换策略

```
LRU (Least Recently Used):
  - 替换最久未使用的块
  - 精度高，但实现复杂

FIFO (First In First Out):
  - 替换最老的块
  - 实现简单，但精度较低

随机替换：
  - 随机选择替换块
  - 实现最简单，但性能最差

Clock（二次机会）：
  - 结合LRU的简化版本
  - 性能接近LRU，实现更简单
```

## 3.6.3 指令级并行性的提升

### 乱序执行的考量

```
顺序执行（当前Coral NPU）：
- 指令必须按顺序完成
- 简单，功耗低
- 但无法隐藏长延迟依赖

乱序执行（可选扩展）：
- 指令可以乱序执行但顺序完成
- 复杂度增加（Reorder Buffer, 唤醒逻辑等）
- 性能提升，但功耗增加

决策因素：
  如果瓶颈是数据依赖，考虑乱序执行
  如果瓶颈是指令分布不均（少乘法指令），维持顺序执行
```

### 超标量（Superscalar）扩展

```
当前Coral NPU：
- 每周期dispatch 1-2条指令
- Writeback端口8个

超标量扩展：
- 增加dispatch宽度（如4-5条/周期）
- 增加Writeback宽度
- 增加执行单元

成本：
- 指数级增加的控制逻辑
- 功耗显著增加
- 面积增加
- 频率可能降低（关键路径加长）

收益：
- ILP提升，但有上限（通常不超过3-4×）
- 对有大量独立指令的工作负载有效
```

## 3.6.4 能耗优化

### 动态电压与频率调整（DVFS）

```
工作点的选择：
  功耗 = 动态功耗 + 静态功耗
       = C × V² × f + V × I_leak

动态调整：
- 高性能模式：高频率、高电压
  用于需要高性能的任务

- 低功耗模式：低频率、低电压  
  用于后台任务或空闲时

收益：
- 神经网络推理：可以在较低频率运行，节省功耗
- 动态响应工作负载特性
```

### 时钟门控与功耗域

```
时钟门控的应用：
1. 模块级门控：
   - LSU空闲时关闭其时钟
   - MLU空闲时关闭其时钟

2. 管道级门控：
   - 当缓冲区满时，关闭上一级的时钟

收益：
- 减少动态功耗（转换功耗）
- 减少漏电功耗（静态功耗）
```

## 3.6.5 系统级优化

### 互连带宽的优化

```
当前设计的瓶颈可能在：
- RegisterFile的读写端口带宽
- Cache与主存的带宽
- 向量执行引擎对内存的访问

优化策略：
1. 增加端口数（面积代价）
2. 提升内存总线带宽
3. 改进缓存预取
4. 使用多级缓存（L2, L3）
```

## 小结

微体系结构优化涉及复杂的权衡。建模框架的优势在于能够快速评估各种优化的效果，避免盲目的硬件投入。通过改进分支预测、缓存配置、和能耗管理，可以显著提升处理器性能。

---

**下一节**: [3.7 标量与向量的集成设计](./3.7-标量与向量的集成设计.md)